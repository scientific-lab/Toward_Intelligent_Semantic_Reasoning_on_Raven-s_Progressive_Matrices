# Toward_Explainable_Intelligent_Reasoning_on_RAVEN_Datasets
Human relies on generalizable hierarchical perception and abstract reasoning abilities to answer complicated Raven's Progressive Matrices. In this article, We build explainable algorithms to approximate this human reasoning process. Our model implements human-like transferable object perception and domain-general rule application through Explainable-VAE (E-VAE) feature extraction model and cognitive-map reasoning back end. The E-VAE module is supervised. It extracts explainable features and represents individual objects with generalizable dimensions. We can use these dimensions to interact with objects' images and create unseen objects. The cognitive-map back-end binds the explainable features to general cognitive maps and makes inferences. It reasons at an abstract level and produces clear steps on how and why an answer is selected. The model generates answers and possible images for RAVEN problems in a human-like explainable way with high accuracy. It transfers well to unseen domains and has the potential to adapt to real-life situations. We intend to make the model more biologically possible in the future.
"# Toward_Intelligent_Semantic_Reasoning_on_Raven-s_Progressive_Matrices" 
